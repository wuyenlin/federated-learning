{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CIFAR10_ResNet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMxD1q4b6+h1ZVw8RAwCI6M",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seyrankhademi/ResNet_CIFAR10/blob/master/CIFAR10_ResNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Fe37K5CtO0g",
        "colab_type": "text"
      },
      "source": [
        "#Reproducing CIFAR10 Experiment in the ResNet paper\n",
        "\n",
        "In this notebook we reproduce Table 6 in \n",
        "[original ResNet paper](https://arxiv.org/abs/1512.03385), \n",
        "i.e. the [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html)\n",
        "experiment in the original ResNet paper \n",
        "published in CVPR 2016 conference andreceived \n",
        "more than 38k citations so far. This ```Pytorch```\n",
        "implementation started from the code in \n",
        "[torchvision tutorial]( https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py) and the implementation by \n",
        "[Yerlan Idelbayev](https://github.com/akamaster/pytorch_resnet_cifar10). \n",
        "We developed the code in Jupyter notebook and it \n",
        "is compatible with Google Colab platform to be used with GPU. \n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## How/Why ResNet models are working?\n",
        "There have been rigorous attempts to make deeper \n",
        "convolutional neural networks (CNN) since their \n",
        "advent in [2012](https://dl.acm.org/doi/10.1145/3065386) as \n",
        "the performance is believed to be tightly related to the  [complexity of the network](https://arxiv.org/abs/1409.1556). \n",
        "A major obstacle in training deeper neural networks is the well-known  [vanishing gradient](http://proceedings.mlr.press/v9/glorot10a.html) problem. \n",
        "As the layers are added to the network the \n",
        "multiplying gradients make the overall gradient \n",
        "infinitesimal which in turn causes very slow \n",
        "convergence if at all. \n",
        "\n",
        "The same training difficulties with *exploding gradients* \n",
        "can also hinder the learning process once layers are stacked in the \n",
        "neural networks. In an attempt to tackle the vanishing/exploding \n",
        "gradients in deeper networks, in 2015, a novel CNN architecture \n",
        "is introduced, which won the ImageNet classification \n",
        "competition in [ILSVRC 2015](https://arxiv.org/abs/1502.01852) by \n",
        "a good margin (2.84 %) from its competitors. \n",
        "\n",
        "The intuition behind the ResNet architecture is \n",
        "rather simple: Assuming that a neural network unit \n",
        "can learn any function, asymptotically, then it can learn the identity function as well. Why is it \n",
        "important to learn the identity function? The \n",
        "answer lies in the ResNet architecture. An example \n",
        "of a residual unit is shown in the following figure, \n",
        "taken from the paper. The input to the residual \n",
        "block is $X$ and the output is $\\mathcal{F}(X)+X$, \n",
        "therefore, by learning $\\mathcal{F}(X)=0$ this basic \n",
        "block is bypassed during the training process,which is equivalent to identity mapping. A cascade of these residual blocks is used \n",
        "to create very deep CNN models with more than 100 \n",
        "layers as presented in the original ResNet paper. \n",
        "\n",
        "<img align=\"center\" src=\"https://drive.google.com/uc?id=1c4QvJN4H_GdGWNM-vW46j_JIG64CD_mD\" />\n",
        "\n",
        "Note that a plain CNN model (without residual connections)posses the same solution space as the counterpart network \n",
        "with the residual connections, however, it is argued in \n",
        "[original ResNet paper](https://arxiv.org/abs/1512.03385) that \"If the optimal function is closer to an identity\n",
        "mapping than to a zero mapping, it should be easier for the\n",
        "solver to find the perturbations with reference to an identity\n",
        "mapping , than to learn the function like a new one.\n",
        "\" This hypothesis is backed up in the paper with \n",
        "several experiments in different datasets.\n",
        "In essence, the ResNet model gives a chance to the \n",
        "network to learn \"flexible\" depth for the CNN model \n",
        "and avoid the vanishing/exploding gradients if that \n",
        "hinders the optimization process. \n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## Experiment Setup \n",
        "The authors train and test six different ResNet architectures for \n",
        "[CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html) and \n",
        "compare the results in Table 6 in the original paper.CIFAR10 image classification dataset consists of 50k training \n",
        "images and 10k testing images in 10 classes. The network inputs \n",
        "are $32\u0002\\times 32$ images, with the per-pixel mean subtracted. \n",
        "The first layer is $3\u0002\\times 3$ convolutions.\n",
        "There are totally $6n+2$ residual blocks stacked, \n",
        "where replacing $n$ with $3,5,7,9,18,200$ produces \n",
        "networks of depth $20,32,44,56,110,1202$ respectively. \n",
        "The architecture is summarized in the following table \n",
        "taken from the paper, where three columns represent \n",
        "three different feature-map sizes. \n",
        "\n",
        "<img align=\"center\" src=\"https://drive.google.com/uc?id=1W_k5HZ8lS9_h9BUOx9R0AvZPTqRVDSlT\" />\n",
        "\n",
        "Note that training in the original paper uses \n",
        "validation set to select the best performing model, \n",
        "however, this implementation does not use \n",
        "validation set to select the model, rather we \n",
        "use the train and validation set for training \n",
        "and testing the performance of a single model \n",
        "(reported in the paper). Also to train ResNet1202, \n",
        "you need 16GB memory on GPU, therefore, you can \n",
        "not run it on the Google CoLab platform.\n",
        "For the rest,we use the same setting as \n",
        "described in the original paper and we \n",
        "reproduce the following results in terms \n",
        "of performance error: \n",
        "\n",
        "| MODEL | PAPER   | OURS\n",
        "|------|------||\n",
        "|   ResNet-20  | 8.75|7.92|\n",
        "|   ResNet-32  |7.51 |7.27|\n",
        "|   ResNet-44  |7.17|6.88|\n",
        "|   ResNet-56  |6.97 |7.58|\n",
        "|   ResNet-110  | 6.43|6.54|\n",
        "|   ResNet-1202  | 7.93|?|\n",
        "\n",
        "Except for the ResNet1202, we reproduced the \n",
        "experiments with comparable or better results. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XAEdiF4Ymizi",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## Running the Experiment on Google Colab\n",
        "This notebook is running remotely on the Google Colab platform, therefore to save and access the trained model and checkpoints in your local computer you may need to mount the Google drive (gdrive). I used the following code snippet to set up a local drive on my computer. You need to do the same by specifying the path to your project directory.  Therefore, you need to create a directory in your gdrive for this project and change the paths in the code to your directory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H418uCYl6OlQ",
        "colab_type": "code",
        "outputId": "23635f09-5239-4348-832f-6346569f7d72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "# First we need to mount the Google drive \n",
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "# Here specify the path to your directory\n",
        "!ls \"/content/gdrive/My Drive/CIFAR10_ResNet\" \n",
        "root_path = 'gdrive/My Drive/CIFAR10_ResNet' \n",
        "path ='/content/gdrive/My Drive/CIFAR10_ResNet'\n",
        "os.chdir(path)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n",
            "data\t\t   pretrained_models.zip  README.md  run.sh\ttest.png\n",
            "pretrained_models  __pycache__\t\t  resnet.py  save_temp\ttrainer.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjvbl18HsjnT",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "## ResNet Architecture\n",
        "\n",
        "In the following code cell, the ResNet model is defined with all the related functions for initialization of the weights, the residual block and skip connections are implemented as presented in the original paper. By executing the cell you can see all possible ResNet architecture, with the number of their learning parameters and layers, that we use in this experiment. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9Y2hYRwB-qg",
        "colab_type": "code",
        "outputId": "6c8ccb56-a6d9-44bb-a13f-47b165e803ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "import resnet\n",
        "# We define all the classes and function regarding the ResNet architecture in this code cell\n",
        "__all__ = ['ResNet', 'resnet20', 'resnet32', 'resnet44', 'resnet56', 'resnet110', 'resnet1202']\n",
        " \n",
        "def _weights_init(m):\n",
        "    \"\"\"\n",
        "        Initialization of CNN weights\n",
        "    \"\"\"\n",
        "    classname = m.__class__.__name__\n",
        "    if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d):\n",
        "        init.kaiming_normal_(m.weight)\n",
        "\n",
        "\n",
        "class LambdaLayer(nn.Module):\n",
        "    \"\"\"\n",
        "      Identity mapping between ResNet blocks with diffrenet size feature map\n",
        "    \"\"\"\n",
        "    def __init__(self, lambd):\n",
        "        super(LambdaLayer, self).__init__()\n",
        "        self.lambd = lambd\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.lambd(x)\n",
        "\n",
        "# A basic block as shown in Fig.3 (right) in the paper consists of two convolutional blocks, each followed by a Bach-Norm layer. \n",
        "# Every basic block is shortcuted in ResNet architecture to construct f(x)+x module. \n",
        "# Expansion for option 'A' in the paper is equal to identity with extra zero entries padded\n",
        "# for increasing dimensions between layers with different feature map size. This option introduces no extra parameter. \n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1, option='A'):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != planes:\n",
        "            if option == 'A':\n",
        "                \"\"\"\n",
        "                For CIFAR10 experiment, ResNet paper uses option A.\n",
        "                \"\"\"\n",
        "                self.shortcut = LambdaLayer(lambda x:\n",
        "                                            F.pad(x[:, :, ::2, ::2], (0, 0, 0, 0, planes//4, planes//4), \"constant\", 0))\n",
        "            elif option == 'B':\n",
        "                self.shortcut = nn.Sequential(\n",
        "                     nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\n",
        "                     nn.BatchNorm2d(self.expansion * planes)\n",
        "                )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "# Stack of 3 times 2*n (n is the number of basic blocks) layers are used for making the ResNet model, \n",
        "# where each 2n layers have feature maps of size {16,32,64}, respectively. \n",
        "# The subsampling is performed by convolutions with a stride of 2.\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=10):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_planes = 16\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(16)\n",
        "        self.layer1 = self._make_layer(block, 16, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 32, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 64, num_blocks[2], stride=2)\n",
        "        self.linear = nn.Linear(64, num_classes)\n",
        "        self.apply(_weights_init)\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes * block.expansion\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = F.avg_pool2d(out, out.size()[3])\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "def resnet20():\n",
        "    return ResNet(BasicBlock, [3, 3, 3])\n",
        "\n",
        "\n",
        "def resnet32():\n",
        "    return ResNet(BasicBlock, [5, 5, 5])\n",
        "\n",
        "\n",
        "def resnet44():\n",
        "    return ResNet(BasicBlock, [7, 7, 7])\n",
        "\n",
        "\n",
        "def resnet56():\n",
        "    return ResNet(BasicBlock, [9, 9, 9])\n",
        "\n",
        "\n",
        "def resnet110():\n",
        "    return ResNet(BasicBlock, [18, 18, 18])\n",
        "\n",
        "\n",
        "def resnet1202():\n",
        "    return ResNet(BasicBlock, [200, 200, 200])\n",
        "\n",
        "\n",
        "def test(net):\n",
        "    total_params = 0\n",
        "\n",
        "    for x in filter(lambda p: p.requires_grad, net.parameters()):\n",
        "        total_params += np.prod(x.data.numpy().shape)\n",
        "    print(\"Total number of params\", total_params)\n",
        "    print(\"Total layers\", len(list(filter(lambda p: p.requires_grad and len(p.data.size())>1, net.parameters()))))\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    for net_name in __all__:\n",
        "        if net_name.startswith('resnet'):\n",
        "            print(net_name)\n",
        "            test(globals()[net_name]())\n",
        "            print()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "resnet20\n",
            "Total number of params 269722\n",
            "Total layers 20\n",
            "\n",
            "resnet32\n",
            "Total number of params 464154\n",
            "Total layers 32\n",
            "\n",
            "resnet44\n",
            "Total number of params 658586\n",
            "Total layers 44\n",
            "\n",
            "resnet56\n",
            "Total number of params 853018\n",
            "Total layers 56\n",
            "\n",
            "resnet110\n",
            "Total number of params 1727962\n",
            "Total layers 110\n",
            "\n",
            "resnet1202\n",
            "Total number of params 19421274\n",
            "Total layers 1202\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ANRMm1zq2J7a",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "---\n",
        "# Hyperparameter Setting\n",
        "\n",
        "We define a class referred to as ```MyResNetArgs```in the following to assign the hyperparameters such as a number of training epochs, learning rate, momentum, batch size, etc. to the training function. The objects of this class are initialized inherently once created with a void argument. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iIXmCsEZ6dFV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " class MyResNetArgs:\n",
        "   \"\"\"\n",
        "    Passing the hyperparameters to the model\n",
        "   \"\"\"\n",
        "   def __init__(self, arch='resnet20' ,epochs=200, start_epoch=0, batch_size=128, lr=0.1, momentum=0.9, weight_decay=1e-4, print_freq=55,\n",
        "                 evaluate=0, pretrained=0, half=0, save_dir='save_temp', save_every=10):\n",
        "        self.save_every = save_every #Saves checkpoints at every specified number of epochs\n",
        "        self.save_dir = save_dir #The directory used to save the trained models\n",
        "        self.half = half #use half-precision(16-bit)\n",
        "        self.evaluate = evaluate #evaluate model on the validation set\n",
        "        self.pretrained = pretrained #evaluate the pretrained model on the validation set\n",
        "        self.print_freq = print_freq #print frequency \n",
        "        self.weight_decay = weight_decay\n",
        "        self.momentum = momentum \n",
        "        self.lr = lr #Learning rate\n",
        "        self.batch_size = batch_size \n",
        "        self.start_epoch = start_epoch\n",
        "        self.epochs = epochs\n",
        "        self.arch = arch #ResNet model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PpNzFe-13pWj",
        "colab_type": "text"
      },
      "source": [
        "Now we can create an instance of ResNet model and inspect the architecture by printing the model summary. \n",
        "One can easily check the difference between different ResNet models to understand the construction units. There are totally $6n+2$ stacked weighted layers, e.g., for ResNet 20, there are 19 convolutional layers plus one fully connected layer. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "djW0RO80_prY",
        "colab_type": "code",
        "outputId": "1d040e0e-dd21-415b-a599-cb39a040a5d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from torchsummary import summary\n",
        "args=MyResNetArgs('resnet20',pretrained=0)\n",
        "#model = resnet.__dict__[args.arch]()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
        "model = resnet.__dict__[args.arch]().to(device)\n",
        "summary(model, (3,32,32))\n",
        "best_prec1 = 0"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 16, 32, 32]             432\n",
            "       BatchNorm2d-2           [-1, 16, 32, 32]              32\n",
            "            Conv2d-3           [-1, 16, 32, 32]           2,304\n",
            "       BatchNorm2d-4           [-1, 16, 32, 32]              32\n",
            "            Conv2d-5           [-1, 16, 32, 32]           2,304\n",
            "       BatchNorm2d-6           [-1, 16, 32, 32]              32\n",
            "        BasicBlock-7           [-1, 16, 32, 32]               0\n",
            "            Conv2d-8           [-1, 16, 32, 32]           2,304\n",
            "       BatchNorm2d-9           [-1, 16, 32, 32]              32\n",
            "           Conv2d-10           [-1, 16, 32, 32]           2,304\n",
            "      BatchNorm2d-11           [-1, 16, 32, 32]              32\n",
            "       BasicBlock-12           [-1, 16, 32, 32]               0\n",
            "           Conv2d-13           [-1, 16, 32, 32]           2,304\n",
            "      BatchNorm2d-14           [-1, 16, 32, 32]              32\n",
            "           Conv2d-15           [-1, 16, 32, 32]           2,304\n",
            "      BatchNorm2d-16           [-1, 16, 32, 32]              32\n",
            "       BasicBlock-17           [-1, 16, 32, 32]               0\n",
            "           Conv2d-18           [-1, 32, 16, 16]           4,608\n",
            "      BatchNorm2d-19           [-1, 32, 16, 16]              64\n",
            "           Conv2d-20           [-1, 32, 16, 16]           9,216\n",
            "      BatchNorm2d-21           [-1, 32, 16, 16]              64\n",
            "      LambdaLayer-22           [-1, 32, 16, 16]               0\n",
            "       BasicBlock-23           [-1, 32, 16, 16]               0\n",
            "           Conv2d-24           [-1, 32, 16, 16]           9,216\n",
            "      BatchNorm2d-25           [-1, 32, 16, 16]              64\n",
            "           Conv2d-26           [-1, 32, 16, 16]           9,216\n",
            "      BatchNorm2d-27           [-1, 32, 16, 16]              64\n",
            "       BasicBlock-28           [-1, 32, 16, 16]               0\n",
            "           Conv2d-29           [-1, 32, 16, 16]           9,216\n",
            "      BatchNorm2d-30           [-1, 32, 16, 16]              64\n",
            "           Conv2d-31           [-1, 32, 16, 16]           9,216\n",
            "      BatchNorm2d-32           [-1, 32, 16, 16]              64\n",
            "       BasicBlock-33           [-1, 32, 16, 16]               0\n",
            "           Conv2d-34             [-1, 64, 8, 8]          18,432\n",
            "      BatchNorm2d-35             [-1, 64, 8, 8]             128\n",
            "           Conv2d-36             [-1, 64, 8, 8]          36,864\n",
            "      BatchNorm2d-37             [-1, 64, 8, 8]             128\n",
            "      LambdaLayer-38             [-1, 64, 8, 8]               0\n",
            "       BasicBlock-39             [-1, 64, 8, 8]               0\n",
            "           Conv2d-40             [-1, 64, 8, 8]          36,864\n",
            "      BatchNorm2d-41             [-1, 64, 8, 8]             128\n",
            "           Conv2d-42             [-1, 64, 8, 8]          36,864\n",
            "      BatchNorm2d-43             [-1, 64, 8, 8]             128\n",
            "       BasicBlock-44             [-1, 64, 8, 8]               0\n",
            "           Conv2d-45             [-1, 64, 8, 8]          36,864\n",
            "      BatchNorm2d-46             [-1, 64, 8, 8]             128\n",
            "           Conv2d-47             [-1, 64, 8, 8]          36,864\n",
            "      BatchNorm2d-48             [-1, 64, 8, 8]             128\n",
            "       BasicBlock-49             [-1, 64, 8, 8]               0\n",
            "           Linear-50                   [-1, 10]             650\n",
            "================================================================\n",
            "Total params: 269,722\n",
            "Trainable params: 269,722\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 3.63\n",
            "Params size (MB): 1.03\n",
            "Estimated Total Size (MB): 4.67\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TAb3r6OQ43ve",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "# Training and Validation\n",
        "The next two code blocks (```train``` and ```validate```) are for training and testing the model on the validation set. There is a print module at the end of the train function which prints the top-k classification accuracy and error at specified epochs. The checkpoints are also saved for the training model at ```save_every``` epoch steps, which is initialized to every $10$ epoch by default.  The average accuracy among mini-batches is also recorded for inspection purposes, which is calculated using the ```AverageMeter``` class. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTjp-tkWtmmI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(train_loader, model, criterion, optimizer, epoch):\n",
        "    \"\"\"\n",
        "        Run one train epoch\n",
        "    \"\"\"\n",
        "    batch_time = AverageMeter()\n",
        "    data_time = AverageMeter()\n",
        "    losses = AverageMeter()\n",
        "    top1 = AverageMeter()\n",
        "\n",
        "    # switch to train mode\n",
        "    model.train()\n",
        "\n",
        "    end = time.time()\n",
        "    for i, (input, target) in enumerate(train_loader):\n",
        "\n",
        "        # measure data loading time\n",
        "        data_time.update(time.time() - end)\n",
        "\n",
        "        target = target.cuda()\n",
        "        input_var = input.cuda()\n",
        "        target_var = target\n",
        "        if args.half:\n",
        "            input_var = input_var.half()\n",
        "\n",
        "        # compute output\n",
        "        output = model(input_var)\n",
        "        loss = criterion(output, target_var)\n",
        "\n",
        "        # compute gradient and do SGD step\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        output = output.float()\n",
        "        loss = loss.float()\n",
        "        # measure accuracy and record loss\n",
        "        prec1 = accuracy(output.data, target)[0]\n",
        "        losses.update(loss.item(), input.size(0))\n",
        "        top1.update(prec1.item(), input.size(0))\n",
        "\n",
        "        # measure elapsed time\n",
        "        batch_time.update(time.time() - end)\n",
        "        end = time.time()\n",
        "\n",
        "        if i % args.print_freq == 0:\n",
        "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
        "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
        "                  'Prec@1 {top1.val:.3f} ({top1.avg:.3f})'.format(\n",
        "                      epoch, i, len(train_loader), batch_time=batch_time,\n",
        "                      data_time=data_time, loss=losses, top1=top1))\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B57y5hgMtzDe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def validate(val_loader, model, criterion):\n",
        "    \"\"\"\n",
        "    Run evaluation\n",
        "    \"\"\"\n",
        "    batch_time = AverageMeter()\n",
        "    losses = AverageMeter()\n",
        "    top1 = AverageMeter()\n",
        "\n",
        "    # switch to evaluate mode\n",
        "    model.eval()\n",
        "\n",
        "    end = time.time()\n",
        "    with torch.no_grad():\n",
        "        for i, (input, target) in enumerate(val_loader):\n",
        "            target = target.cuda()\n",
        "            input_var = input.cuda()\n",
        "            target_var = target.cuda()\n",
        "\n",
        "            if args.half:\n",
        "                input_var = input_var.half()\n",
        "\n",
        "            # compute output\n",
        "            output = model(input_var)\n",
        "            loss = criterion(output, target_var)\n",
        "\n",
        "            output = output.float()\n",
        "            loss = loss.float()\n",
        "\n",
        "            # measure accuracy and record loss\n",
        "            prec1 = accuracy(output.data, target)[0]\n",
        "            losses.update(loss.item(), input.size(0))\n",
        "            top1.update(prec1.item(), input.size(0))\n",
        "\n",
        "            # measure elapsed time\n",
        "            batch_time.update(time.time() - end)\n",
        "            end = time.time()\n",
        "\n",
        "\n",
        "    print('Test\\t  Prec@1: {top1.avg:.3f} (Err: {error:.3f} )\\n'\n",
        "          .format(top1=top1,error=100-top1.avg))\n",
        "\n",
        "    return top1.avg\n",
        "\n",
        "def save_checkpoint(state, filename='checkpoint.th'):\n",
        "    \"\"\"\n",
        "    Save the training model\n",
        "    \"\"\"\n",
        "    torch.save(state, filename)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKt6Q9Zlt8MU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "\n",
        "def accuracy(output, target, topk=(1,)):\n",
        "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
        "    maxk = max(topk)\n",
        "    batch_size = target.size(0)\n",
        "\n",
        "    _, pred = output.topk(maxk, 1, True, True)\n",
        "    pred = pred.t()\n",
        "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
        "\n",
        "    res = []\n",
        "    for k in topk:\n",
        "        correct_k = correct[:k].view(-1).float().sum(0)\n",
        "        res.append(correct_k.mul_(100.0 / batch_size))\n",
        "    return res\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RwM5UxsVXdRd",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## Dataset \n",
        "\n",
        "Now that we defined our ResNet model, we need to download and prepare [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html) dataset to start the experiment. This is impressively easy with ```\n",
        "torchvision```. We use ```Dataloader``` to download the train and the validation set. We show random samples in a batch of training images for a better understanding of data. Note that CIFAR-10 images are quite small in size $32 \\times 32$. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5R-ck_wWQDD",
        "colab_type": "code",
        "outputId": "31b51227-603c-4e89-94e4-582cff166dec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        }
      },
      "source": [
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                     std=[0.229, 0.224, 0.225])\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "        datasets.CIFAR10(root='./data', train=True, transform=transforms.Compose([\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.RandomCrop(32, 4),\n",
        "            transforms.ToTensor(),\n",
        "            normalize,\n",
        "        ]), download=True),\n",
        "        batch_size=args.batch_size, shuffle=True,\n",
        "        num_workers=4, pin_memory=True)\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "        datasets.CIFAR10(root='./data', train=False, transform=transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            normalize,\n",
        "        ])),\n",
        "        batch_size=128, shuffle=False,\n",
        "        num_workers=4, pin_memory=True)\n",
        "\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "# functions to show an image\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "\n",
        "\n",
        "# get some random training images\n",
        "dataiter = iter(train_loader)\n",
        "images, labels = dataiter.next()\n",
        "plt.figure(figsize=(20,10)) \n",
        "\n",
        "# show images\n",
        "imshow(torchvision.utils.make_grid(images[0:8,:,:]))\n",
        "# print labels\n",
        "print(' '.join('%15s' % classes[labels[j]] for j in range(8)))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "           ship           plane             dog            ship           plane           plane            frog            frog\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAACPwAAAFmCAYAAADz4hazAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAAAAALCQr2cRT4hLZaK5AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 1440x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "image/png": {
              "width": 1150,
              "height": 179
            }
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4OKFeRNm7mJA",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "# Running the Experiment\n",
        "Here comes the main script using all the functions explained above to execute the train and the test procedure for a specified ResNet model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OONRZVaZtP0f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "\n",
        "def main():\n",
        "    global args, best_prec1\n",
        "    \n",
        "    # Check the save_dir exists or not\n",
        "    if not os.path.exists(args.save_dir):\n",
        "        os.makedirs(args.save_dir)\n",
        "\n",
        "    model = resnet.__dict__[args.arch]()\n",
        "    model.cuda()\n",
        "\n",
        "\n",
        "    # define loss function (criterion) and pptimizer\n",
        "    criterion = nn.CrossEntropyLoss().cuda()\n",
        "\n",
        "    if args.half:\n",
        "        print('half persicion is used.')\n",
        "        model.half()\n",
        "        criterion.half()\n",
        "\n",
        "    optimizer = torch.optim.SGD(model.parameters(), args.lr,\n",
        "                                momentum=args.momentum,\n",
        "                                weight_decay=args.weight_decay)\n",
        "\n",
        "    lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer,\n",
        "                                                        milestones=[100, 150], last_epoch=args.start_epoch - 1)\n",
        "\n",
        "    if args.arch in ['resnet1202']:\n",
        "        # for resnet1202 original paper uses lr=0.01 for first 400 minibatches for warm-up\n",
        "        # then switch back. In this setup it will correspond for first epoch.\n",
        "        for param_group in optimizer.param_groups:\n",
        "            param_group['lr'] = args.lr*0.1\n",
        "\n",
        "\n",
        "    if args.evaluate:\n",
        "        print('evalution mode')\n",
        "        model.load_state_dict(torch.load(os.path.join(args.save_dir, 'model.th')))\n",
        "        best_prec1 = validate(val_loader, model, criterion)\n",
        "        return best_prec1\n",
        "\n",
        "    if args.pretrained:\n",
        "        print('evalution of pretrained model')\n",
        "        args.save_dir='pretrained_models'\n",
        "        pretrained_model= args.arch +'.th'\n",
        "        model.load_state_dict(torch.load(os.path.join(args.save_dir, pretrained_model)))\n",
        "        best_prec1 = validate(val_loader, model, criterion)\n",
        "        return best_prec1\n",
        "\n",
        "    for epoch in range(args.start_epoch, args.epochs):\n",
        "\n",
        "        # train for one epoch\n",
        "        print('Training {} model'.format(args.arch))\n",
        "        print('current lr {:.5e}'.format(optimizer.param_groups[0]['lr']))\n",
        "        train(train_loader, model, criterion, optimizer, epoch)\n",
        "        lr_scheduler.step()\n",
        "\n",
        "        # evaluate on validation set\n",
        "        prec1 = validate(val_loader, model, criterion)\n",
        "\n",
        "        # remember best prec@1 and save checkpoint\n",
        "        is_best = prec1 > best_prec1\n",
        "        best_prec1 = max(prec1, best_prec1)\n",
        "\n",
        "        if epoch > 0 and epoch % args.save_every == 0:\n",
        "            save_checkpoint(model.state_dict(), filename=os.path.join(args.save_dir, 'checkpoint.th'))\n",
        "        if is_best:\n",
        "            save_checkpoint(model.state_dict(), filename=os.path.join(args.save_dir, 'model.th'))\n",
        "\n",
        "    return best_prec1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Su50THmTmXMh",
        "colab_type": "text"
      },
      "source": [
        "Since Google Colab imposes time restriction, we can not loop over all ResNet models to reproduce the results in one go, instead, we run each ResNet model separately by setting the name of the model (e.g. resnet20)  manually in the hyperparameters and record the results once training is finished for the specified network. We saved the trained models in a separate directory to do the inference later. One can try to run the main script several times for each network and report the mean and the variance performance for more reliable results. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkntiMU2uKk6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if __name__ == '__main__':\n",
        "   best_prec1 = main()\n",
        "   print('The lowest error from {} model after {} epochs is {error:.3f}'.format(args.arch,args.epochs,error=100-best_prec1)) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNU4-9Tvzg4Z",
        "colab_type": "text"
      },
      "source": [
        "We conclude here that the results from the original ResNet paper are reproducible for the CIFAR-10 dataset. \n",
        "\n",
        "\n"
      ]
    }
  ]
}